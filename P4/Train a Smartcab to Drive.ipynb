{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#347797\">Train a Smartcab How to Drive</font>\n",
    "\n",
    "A smartcab is a self-driving car from the not-so-distant future that ferries people from one arbitrary location to another. In this project, you will use reinforcement learning to train a smartcab how to drive.\n",
    "\n",
    "## Environment\n",
    "\n",
    "Your smartcab operates in an idealized grid-like city, with roads going North-South and East-West. Other vehicles may be present on the roads, but no pedestrians. There is a traffic light at each intersection that can be in one of two states: North-South open or East-West open.\n",
    "\n",
    "US right-of-way rules apply: On a green light, you can turn left only if there is no oncoming traffic at the intersection coming straight. On a red light, you can turn right if there is no oncoming traffic turning left or traffic from the left going straight.\n",
    "\n",
    "To understand how to correctly yield to oncoming traffic when turning left, you may refer to this [official drivers’ education video](https://www.youtube.com/watch?v=TW0Eq2Q-9Ac), or this [passionate exposition](https://www.youtube.com/watch?v=0EdkxI6NeuA).\n",
    "\n",
    "## Inputs\n",
    "\n",
    "Assume that a higher-level planner assigns a route to the smartcab, splitting it into waypoints at each intersection. And time in this world is quantized. At any instant, the smartcab is at some intersection. Therefore, the next waypoint is always either one block straight ahead, one block left, one block right, one block back or exactly there (reached the destination).\n",
    "\n",
    "The smartcab only has an egocentric view of the intersection it is currently at (sorry, no accurate GPS, no global location). It is able to sense whether the traffic light is green for its direction of movement (heading), and whether there is a car at the intersection on each of the incoming roadways (and which direction they are trying to go).\n",
    "\n",
    "In addition to this, each trip has an associated timer that counts down every time step. If the timer is at 0 and the destination has not been reached, the trip is over, and a new one may start.\n",
    "\n",
    "## Outputs\n",
    "\n",
    "At any instant, the smartcab can either stay put at the current intersection, move one block forward, one block left, or one block right (no backward movement).\n",
    "\n",
    "## Rewards\n",
    "\n",
    "The smartcab gets a reward for each successfully completed trip. A trip is considered “successfully completed” if the passenger is dropped off at the desired destination (some intersection) within a pre-specified time bound (computed with a route plan).\n",
    "\n",
    "It also gets a smaller reward for each correct move executed at an intersection. It gets a small penalty for an incorrect move, and a larger penalty for violating traffic rules and/or causing an accident.\n",
    "\n",
    "## Goal\n",
    "\n",
    "Design the AI driving agent for the smartcab. It should receive the above-mentioned inputs at each time step t, and generate an output move. Based on the rewards and penalties it gets, the agent should learn an optimal policy for driving on city roads, obeying traffic rules correctly, and trying to reach the destination within a goal time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#347797\">Tasks</font>\n",
    "\n",
    "Download [smartcab.zip](https://s3.amazonaws.com/content.udacity-data.com/courses/nd009/projects/smartcab.zip), unzip and open the template Python file agent.py (do not modify any other file). Perform the following tasks to build your agent, referring to instructions mentioned in README.md as well as inline comments in agent.py.\n",
    "\n",
    "Also create a project report (e.g. Word or Google doc), and start addressing the questions indicated in italics below. When you have finished the project, save/download the report as a PDF and turn it in with your code.\n",
    "\n",
    "## Implement a basic driving agent\n",
    "\n",
    "Implement the basic driving agent, which processes the following inputs at each time step:\n",
    "\n",
    "- Next waypoint location, relative to its current location and heading,\n",
    "- Intersection state (traffic light and presence of cars), and,\n",
    "- Current deadline value (time steps remaining),\n",
    "\n",
    "And produces some random move/action (None, 'forward', 'left', 'right'). Don’t try to implement the correct strategy! That’s exactly what your agent is supposed to learn.\n",
    "\n",
    "Run this agent within the simulation environment with enforce_deadline set to False (see run function in agent.py), and observe how it performs. In this mode, the agent is given unlimited time to reach the destination. The current state, action taken by your agent and reward/penalty earned are shown in the simulator.\n",
    "\n",
    "*In your report, mention what you see in the agent’s behavior. Does it eventually make it to the target location?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "We are producing a random move/action from the valid actions of the environment. The simulation can only produce a random walk until it accidentally falls on the destination. It doesn't matter what is the next waypoint, the current intersection state or the current deadline value, we are producing a random action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify and update state\n",
    "\n",
    "Identify a set of states that you think are appropriate for modeling the driving agent. The main source of state variables are current inputs, but not all of them may be worth representing. Also, you can choose to explicitly define states, or use some combination (vector) of inputs as an implicit state.\n",
    "\n",
    "At each time step, process the inputs and update the current state. Run it again (and as often as you need) to observe how the reported state changes through the run.\n",
    "\n",
    "*Justify why you picked these set of states, and how they model the agent and its environment.* \n",
    "\n",
    "**Answer**\n",
    "\n",
    "I have chosen to use the next way point in the state as a way to get to the destination. The GPS telling you what is the next step. Otherwise the agent has no idea where to go.\n",
    "I have put the light as another factor so it learns that going through a red light is bad.\n",
    "Direction of the surrounding traffic is also important to in order to respect the rules of driving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Q-Learning\n",
    "\n",
    "Implement the Q-Learning algorithm by initializing and updating a table/mapping of Q-values at each time step. Now, instead of randomly selecting an action, pick the best action available from the current state based on Q-values, and return that.\n",
    "\n",
    "Each action generates a corresponding numeric reward or penalty (which may be zero). Your agent should take this into account when updating Q-values. Run it again, and observe the behavior.\n",
    "\n",
    "*What changes do you notice in the agent’s behavior?*\n",
    "\n",
    "## Enhance the driving agent\n",
    "\n",
    "Apply the reinforcement learning techniques you have learnt, and tweak the parameters (e.g. learning rate, discount factor, action selection method, etc.), to improve the performance of your agent. Your goal is to get it to a point so that within 100 trials, the agent is able to learn a feasible policy - i.e. reach the destination within the allotted time, with net reward remaining positive.\n",
    "\n",
    "*Report what changes you made to your basic implementation of Q-Learning to achieve the final version of the agent. How well does it perform?*\n",
    "\n",
    "*Does your agent get close to finding an optimal policy, i.e. reach the destination in the minimum possible time, and not incur any penalties?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%load README.md\n",
    "# Train a smartcab how to drive\n",
    "Reinforcement Learning Project\n",
    "\n",
    "## Install\n",
    "\n",
    "This project requires Python 2.7 with the pygame library installed:\n",
    "\n",
    "https://www.pygame.org/wiki/GettingStarted\n",
    "\n",
    "## Run\n",
    "\n",
    "Make sure you are in the top-level `smartcab` directory. Then run:\n",
    "\n",
    "```python smartcab/agent.py```\n",
    "\n",
    "OR:\n",
    "\n",
    "```python -m smartcab.agent```\n",
    "\n",
    "## Develop\n",
    "\n",
    "Open `agent.py` and implement `LearningAgent`. Follow the `TODO`s in there for further instructions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load smartcab/agent.py\n",
    "import random\n",
    "from environment import Agent, Environment\n",
    "from planner import RoutePlanner\n",
    "from simulator import Simulator\n",
    "\n",
    "class LearningAgent(Agent):\n",
    "    \"\"\"An agent that learns to drive in the smartcab world.\"\"\"\n",
    "\n",
    "    def __init__(self, env):\n",
    "        super(LearningAgent, self).__init__(env)  # sets self.env = env, state = None, next_waypoint = None, and a default color\n",
    "        self.color = 'red'  # override color\n",
    "        self.planner = RoutePlanner(self.env, self)  # simple route planner to get next_waypoint\n",
    "        # TODO: Initialize any additional variables here\n",
    "\n",
    "    def reset(self, destination=None):\n",
    "        self.planner.route_to(destination)\n",
    "        # TODO: Prepare for a new trip; reset any variables here, if required\n",
    "        self.planner = RoutePlanner(self.env, self)\n",
    "\n",
    "    def update(self, t):\n",
    "        # Gather inputs\n",
    "        self.next_waypoint = self.planner.next_waypoint()  # from route planner, also displayed by simulator\n",
    "        inputs = self.env.sense(self)\n",
    "        deadline = self.env.get_deadline(self)\n",
    "\n",
    "        # TODO: Update state\n",
    "        \n",
    "        # TODO: Select action according to your policy\n",
    "        action = None\n",
    "\n",
    "        # Execute action and get reward\n",
    "        reward = self.env.act(self, action)\n",
    "\n",
    "        # TODO: Learn policy based on state, action, reward\n",
    "\n",
    "        print \"LearningAgent.update(): deadline = {}, inputs = {}, action = {}, reward = {}\".format(deadline, inputs, action, reward)  # [debug]\n",
    "\n",
    "\n",
    "def run():\n",
    "    \"\"\"Run the agent for a finite number of trials.\"\"\"\n",
    "\n",
    "    # Set up environment and agent\n",
    "    e = Environment()  # create environment (also adds some dummy traffic)\n",
    "    a = e.create_agent(LearningAgent)  # create agent\n",
    "    e.set_primary_agent(a, enforce_deadline=False)  # set agent to track\n",
    "\n",
    "    # Now simulate it\n",
    "    sim = Simulator(e, update_delay=1.0)  # reduce update_delay to speed up simulation\n",
    "    sim.run(n_trials=10)  # press Esc or close pygame window to quit\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load smartcab/environment.py\n",
    "import time\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "\n",
    "from simulator import Simulator\n",
    "\n",
    "class TrafficLight(object):\n",
    "    \"\"\"A traffic light that switches periodically.\"\"\"\n",
    "\n",
    "    valid_states = [True, False]  # True = NS open, False = EW open\n",
    "\n",
    "    def __init__(self, state=None, period=None):\n",
    "        self.state = state if state is not None else random.choice(self.valid_states)\n",
    "        self.period = period if period is not None else random.choice([3, 4, 5])\n",
    "        self.last_updated = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.last_updated = 0\n",
    "\n",
    "    def update(self, t):\n",
    "        if t - self.last_updated >= self.period:\n",
    "            self.state = not self.state  # assuming state is boolean\n",
    "            self.last_updated = t\n",
    "\n",
    "\n",
    "class Environment(object):\n",
    "    \"\"\"Environment within which all agents operate.\"\"\"\n",
    "\n",
    "    valid_actions = [None, 'forward', 'left', 'right']\n",
    "    valid_inputs = {'light': TrafficLight.valid_states, 'oncoming': valid_actions, 'left': valid_actions, 'right': valid_actions}\n",
    "    valid_headings = [(1, 0), (0, -1), (-1, 0), (0, 1)]  # ENWS\n",
    "\n",
    "    def __init__(self):\n",
    "        self.done = False\n",
    "        self.t = 0\n",
    "        self.agent_states = OrderedDict()\n",
    "        self.status_text = \"\"\n",
    "\n",
    "        # Road network\n",
    "        self.grid_size = (8, 6)  # (cols, rows)\n",
    "        self.bounds = (1, 1, self.grid_size[0], self.grid_size[1])\n",
    "        self.block_size = 100\n",
    "        self.intersections = OrderedDict()\n",
    "        self.roads = []\n",
    "        for x in xrange(self.bounds[0], self.bounds[2] + 1):\n",
    "            for y in xrange(self.bounds[1], self.bounds[3] + 1):\n",
    "                self.intersections[(x, y)] = TrafficLight()  # a traffic light at each intersection\n",
    "\n",
    "        for a in self.intersections:\n",
    "            for b in self.intersections:\n",
    "                if a == b:\n",
    "                    continue\n",
    "                if (abs(a[0] - b[0]) + abs(a[1] - b[1])) == 1:  # L1 distance = 1\n",
    "                    self.roads.append((a, b))\n",
    "\n",
    "        # Dummy agents\n",
    "        self.num_dummies = 3  # no. of dummy agents\n",
    "        for i in xrange(self.num_dummies):\n",
    "            self.create_agent(DummyAgent)\n",
    "\n",
    "        # Primary agent\n",
    "        self.primary_agent = None  # to be set explicitly\n",
    "        self.enforce_deadline = False\n",
    "\n",
    "    def create_agent(self, agent_class, *args, **kwargs):\n",
    "        \"\"\"Create an agent with random location and heading south\"\"\"\n",
    "        agent = agent_class(self, *args, **kwargs)\n",
    "        self.agent_states[agent] = {'location': random.choice(self.intersections.keys()), 'heading': (0, 1)}\n",
    "        return agent\n",
    "\n",
    "    def set_primary_agent(self, agent, enforce_deadline=False):\n",
    "        self.primary_agent = agent\n",
    "        self.enforce_deadline = enforce_deadline\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the traffic lights, picks a new starting and ending points for the primary agent\n",
    "        and reposition all the other agents.\n",
    "        \"\"\"\n",
    "        self.done = False\n",
    "        self.t = 0\n",
    "\n",
    "        # Reset traffic lights\n",
    "        for traffic_light in self.intersections.itervalues():\n",
    "            traffic_light.reset()\n",
    "\n",
    "        # Pick a start and a destination\n",
    "        start = random.choice(self.intersections.keys())\n",
    "        destination = random.choice(self.intersections.keys())\n",
    "\n",
    "        # Ensure starting location and destination are not too close\n",
    "        while self.compute_dist(start, destination) < 4:\n",
    "            start = random.choice(self.intersections.keys())\n",
    "            destination = random.choice(self.intersections.keys())\n",
    "\n",
    "        start_heading = random.choice(self.valid_headings)\n",
    "        deadline = self.compute_dist(start, destination) * 5\n",
    "        print \"Environment.reset(): Trial set up with start = {}, destination = {}, deadline = {}\".format(start, destination, deadline)\n",
    "\n",
    "        # Initialize agent(s)\n",
    "        for agent in self.agent_states.iterkeys():\n",
    "            self.agent_states[agent] = {\n",
    "                'location': start if agent is self.primary_agent else random.choice(self.intersections.keys()),\n",
    "                'heading': start_heading if agent is self.primary_agent else random.choice(self.valid_headings),\n",
    "                'destination': destination if agent is self.primary_agent else None,\n",
    "                'deadline': deadline if agent is self.primary_agent else None}\n",
    "            agent.reset(destination=(destination if agent is self.primary_agent else None))\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        A step will update the lights at every intersection (turn them on or off), \n",
    "        the agent state (where it's at and it's direction) and check if there is still\n",
    "        time left.\n",
    "        \"\"\"\n",
    "        #print \"Environment.step(): t = {}\".format(self.t)  # [debug]\n",
    "\n",
    "        # Update traffic lights\n",
    "        for intersection, traffic_light in self.intersections.iteritems():\n",
    "            traffic_light.update(self.t)\n",
    "\n",
    "        # Update agents\n",
    "        for agent in self.agent_states.iterkeys():\n",
    "            agent.update(self.t)\n",
    "\n",
    "        self.t += 1\n",
    "        if self.primary_agent is not None:\n",
    "            if self.enforce_deadline and self.agent_states[self.primary_agent]['deadline'] <= 0:\n",
    "                self.done = True\n",
    "                print \"Environment.reset(): Primary agent could not reach destination within deadline!\"\n",
    "            self.agent_states[self.primary_agent]['deadline'] -= 1\n",
    "\n",
    "    def sense(self, agent):\n",
    "        \"\"\"\n",
    "        Checks the environment of an agent, only at the intersection it's at.\n",
    "        Populates the oncoming, left and right traffic.\n",
    "        \"\"\"\n",
    "        assert agent in self.agent_states, \"Unknown agent!\"\n",
    "\n",
    "        state = self.agent_states[agent]\n",
    "        location = state['location']\n",
    "        heading = state['heading']\n",
    "        light = 'green' if (self.intersections[location].state and heading[1] != 0) or ((not self.intersections[location].state) and heading[0] != 0) else 'red'\n",
    "\n",
    "        # Populate oncoming, left, right\n",
    "        oncoming = None\n",
    "        left = None\n",
    "        right = None\n",
    "        for other_agent, other_state in self.agent_states.iteritems():\n",
    "            if agent == other_agent or location != other_state['location'] or (heading[0] == other_state['heading'][0] and heading[1] == other_state['heading'][1]):\n",
    "                continue\n",
    "            other_heading = other_agent.get_next_waypoint()\n",
    "            if (heading[0] * other_state['heading'][0] + heading[1] * other_state['heading'][1]) == -1:\n",
    "                # Might be a bug here, oncoming is always None at this point.\n",
    "                if oncoming != 'left':  # we don't want to override oncoming == 'left'\n",
    "                    oncoming = other_heading\n",
    "            elif (heading[1] == other_state['heading'][0] and -heading[0] == other_state['heading'][1]):\n",
    "                if right != 'forward' and right != 'left':  # we don't want to override right == 'forward or 'left'\n",
    "                    right = other_heading\n",
    "            else:\n",
    "                if left != 'forward':  # we don't want to override left == 'forward'\n",
    "                    left = other_heading\n",
    "\n",
    "        return {'light': light, 'oncoming': oncoming, 'left': left, 'right': right}  # TODO: make this a namedtuple\n",
    "\n",
    "    def get_deadline(self, agent):\n",
    "        return self.agent_states[agent]['deadline'] if agent is self.primary_agent else None\n",
    "\n",
    "    def act(self, agent, action):\n",
    "        assert agent in self.agent_states, \"Unknown agent!\"\n",
    "        assert action in self.valid_actions, \"Invalid action!\"\n",
    "\n",
    "        state = self.agent_states[agent]\n",
    "        location = state['location']\n",
    "        heading = state['heading']\n",
    "        light = 'green' if (self.intersections[location].state and heading[1] != 0) or ((not self.intersections[location].state) and heading[0] != 0) else 'red'\n",
    "\n",
    "        # Move agent if within bounds and obeys traffic rules\n",
    "        reward = 0  # reward/penalty\n",
    "        move_okay = True\n",
    "        if action == 'forward':\n",
    "            if light != 'green':\n",
    "                move_okay = False\n",
    "        elif action == 'left':\n",
    "            if light == 'green':\n",
    "                heading = (heading[1], -heading[0])\n",
    "            else:\n",
    "                move_okay = False\n",
    "        elif action == 'right':\n",
    "            heading = (-heading[1], heading[0])\n",
    "\n",
    "        if action is not None:\n",
    "            if move_okay:\n",
    "                location = ((location[0] + heading[0] - self.bounds[0]) % (self.bounds[2] - self.bounds[0] + 1) + self.bounds[0],\n",
    "                            (location[1] + heading[1] - self.bounds[1]) % (self.bounds[3] - self.bounds[1] + 1) + self.bounds[1])  # wrap-around\n",
    "                #if self.bounds[0] <= location[0] <= self.bounds[2] and self.bounds[1] <= location[1] <= self.bounds[3]:  # bounded\n",
    "                state['location'] = location\n",
    "                state['heading'] = heading\n",
    "                reward = 2 if action == agent.get_next_waypoint() else 0.5\n",
    "            else:\n",
    "                reward = -1\n",
    "        else:\n",
    "            reward = 1\n",
    "\n",
    "        if agent is self.primary_agent:\n",
    "            if state['location'] == state['destination']:\n",
    "                if state['deadline'] >= 0:\n",
    "                    reward += 10  # bonus\n",
    "                self.done = True\n",
    "                print \"Environment.act(): Primary agent has reached destination!\"  # [debug]\n",
    "            self.status_text = \"state: {}\\naction: {}\\nreward: {}\".format(agent.get_state(), action, reward)\n",
    "            #print \"Environment.act() [POST]: location: {}, heading: {}, action: {}, reward: {}\".format(location, heading, action, reward)  # [debug]\n",
    "\n",
    "        return reward\n",
    "\n",
    "    def compute_dist(self, a, b):\n",
    "        \"\"\"L1 distance between two points.\"\"\"\n",
    "        return abs(b[0] - a[0]) + abs(b[1] - a[1])\n",
    "\n",
    "\n",
    "class Agent(object):\n",
    "    \"\"\"Base class for all agents.\"\"\"\n",
    "\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.state = None\n",
    "        self.next_waypoint = None\n",
    "        self.color = 'cyan'\n",
    "\n",
    "    def reset(self, destination=None):\n",
    "        pass\n",
    "\n",
    "    def update(self, t):\n",
    "        pass\n",
    "\n",
    "    def get_state(self):\n",
    "        return self.state\n",
    "\n",
    "    def get_next_waypoint(self):\n",
    "        return self.next_waypoint\n",
    "\n",
    "\n",
    "class DummyAgent(Agent):\n",
    "    color_choices = ['blue', 'cyan', 'magenta', 'orange']\n",
    "\n",
    "    def __init__(self, env):\n",
    "        super(DummyAgent, self).__init__(env)  # sets self.env = env, state = None, next_waypoint = None, and a default color\n",
    "        self.next_waypoint = random.choice(Environment.valid_actions[1:])\n",
    "        self.color = random.choice(self.color_choices)\n",
    "\n",
    "    def update(self, t):\n",
    "        inputs = self.env.sense(self)\n",
    "\n",
    "        action_okay = True\n",
    "        if self.next_waypoint == 'right':\n",
    "            if inputs['light'] == 'red' and inputs['left'] == 'forward':\n",
    "                action_okay = False\n",
    "        elif self.next_waypoint == 'straight':  # This might be a problem. Should be 'forward' (valide_actions)\n",
    "            if inputs['light'] == 'red':\n",
    "                action_okay = False\n",
    "        elif self.next_waypoint == 'left':\n",
    "            if inputs['light'] == 'red' or (inputs['oncoming'] == 'forward' or inputs['oncoming'] == 'right'):\n",
    "                action_okay = False\n",
    "\n",
    "        action = None\n",
    "        if action_okay:\n",
    "            action = self.next_waypoint\n",
    "            self.next_waypoint = random.choice(Environment.valid_actions[1:])\n",
    "        reward = self.env.act(self, action)\n",
    "        #print \"DummyAgent.update(): t = {}, inputs = {}, action = {}, reward = {}\".format(t, inputs, action, reward)  # [debug]\n",
    "        #print \"DummyAgent.update(): next_waypoint = {}\".format(self.next_waypoint)  # [debug]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load smartcab/planner.py\n",
    "class RoutePlanner(object):\n",
    "    \"\"\"Silly route planner that is meant for a perpendicular grid network.\"\"\"\n",
    "\n",
    "    def __init__(self, env, agent):\n",
    "        self.env = env\n",
    "        self.agent = agent\n",
    "        self.destination = None\n",
    "\n",
    "    def route_to(self, destination=None):\n",
    "        self.destination = destination if destination is not None else random.choice(self.env.intersections.keys())\n",
    "        print \"RoutePlanner.route_to(): destination = {}\".format(destination)  # [debug]\n",
    "\n",
    "    def next_waypoint(self):\n",
    "        location = self.env.agent_states[self.agent]['location']\n",
    "        heading = self.env.agent_states[self.agent]['heading']\n",
    "        delta = (self.destination[0] - location[0], self.destination[1] - location[1])\n",
    "        if delta[0] == 0 and delta[1] == 0:\n",
    "            return None\n",
    "        elif delta[0] != 0:  # EW difference\n",
    "            if delta[0] * heading[0] > 0:  # facing correct EW direction\n",
    "                return 'forward'\n",
    "            elif delta[0] * heading[0] < 0:  # facing opposite EW direction\n",
    "                return 'right'  # long U-turn\n",
    "            elif delta[0] * heading[1] > 0:\n",
    "                return 'right'\n",
    "            else:\n",
    "                return 'left'\n",
    "        elif delta[1] != 0:  # NS difference\n",
    "            if delta[1] * heading[1] > 0:  # facing correct NS direction\n",
    "                return 'forward'\n",
    "            elif delta[1] * heading[1] < 0:  # facing opposite NS direction\n",
    "                return 'right'  # long U-turn\n",
    "            elif delta[1] * heading[0] > 0:\n",
    "                return 'right'\n",
    "            else:\n",
    "                return 'left'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load smartcab/simulator.py\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import pygame\n",
    "\n",
    "class Simulator(object):\n",
    "    \"\"\"PyGame-based simulator to create a dynamic environment.\"\"\"\n",
    "\n",
    "    colors = {\n",
    "        'black'   : (  0,   0,   0),\n",
    "        'white'   : (255, 255, 255),\n",
    "        'red'     : (255,   0,   0),\n",
    "        'green'   : (  0, 255,   0),\n",
    "        'blue'    : (  0,   0, 255),\n",
    "        'cyan'    : (  0, 200, 200),\n",
    "        'magenta' : (200,   0, 200),\n",
    "        'yellow'  : (255, 255,   0),\n",
    "        'orange'  : (255, 128,   0)\n",
    "    }\n",
    "\n",
    "    def __init__(self, env, size=None, frame_delay=10, update_delay=1.0):\n",
    "        self.env = env\n",
    "        self.size = size if size is not None else ((self.env.grid_size[0] + 1) * self.env.block_size, (self.env.grid_size[1] + 1) * self.env.block_size)\n",
    "        self.width, self.height = self.size\n",
    "        self.frame_delay = frame_delay\n",
    "\n",
    "        self.bg_color = self.colors['white']\n",
    "        self.road_width = 5\n",
    "        self.road_color = self.colors['black']\n",
    "\n",
    "        self.quit = False\n",
    "        self.start_time = None\n",
    "        self.current_time = 0.0\n",
    "        self.last_updated = 0.0\n",
    "        self.update_delay = update_delay\n",
    "\n",
    "        pygame.init()\n",
    "        self.screen = pygame.display.set_mode(self.size)\n",
    "\n",
    "        self.agent_sprite_size = (32, 32)\n",
    "        self.agent_circle_radius = 10  # radius of circle, when using simple representation\n",
    "        for agent in self.env.agent_states:\n",
    "            agent._sprite = pygame.transform.smoothscale(pygame.image.load(os.path.join(\"images\", \"car-{}.png\".format(agent.color))), self.agent_sprite_size)\n",
    "            agent._sprite_size = (agent._sprite.get_width(), agent._sprite.get_height())\n",
    "\n",
    "        self.font = pygame.font.Font(None, 28)\n",
    "        self.paused = False\n",
    "\n",
    "    def run(self, n_trials=1):\n",
    "        self.quit = False\n",
    "        for trial in xrange(n_trials):\n",
    "            print \"Simulator.run(): Trial {}\".format(trial)  # [debug]\n",
    "            self.env.reset()\n",
    "            self.current_time = 0.0\n",
    "            self.last_updated = 0.0\n",
    "            self.start_time = time.time()\n",
    "            while True:\n",
    "                self.current_time = time.time() - self.start_time\n",
    "                #print \"Simulator.run(): current_time = {:.3f}\".format(self.current_time)\n",
    "                try:\n",
    "                    # Handle events\n",
    "                    for event in pygame.event.get():\n",
    "                        if event.type == pygame.QUIT:\n",
    "                            self.quit = True\n",
    "                        elif event.type == pygame.KEYDOWN:\n",
    "                            if event.key == 27:  # Esc\n",
    "                                self.quit = True\n",
    "                            elif event.unicode == u' ':\n",
    "                                self.paused = True\n",
    "\n",
    "                    if self.paused:\n",
    "                        self.pause()\n",
    "\n",
    "                    # Update environment\n",
    "                    if self.current_time - self.last_updated >= self.update_delay:\n",
    "                        self.env.step()\n",
    "                        self.last_updated = self.current_time\n",
    "\n",
    "                    # Render and sleep\n",
    "                    self.render()\n",
    "                    pygame.time.wait(self.frame_delay)\n",
    "                except KeyboardInterrupt:\n",
    "                    self.quit = True\n",
    "                finally:\n",
    "                    if self.quit or self.env.done:\n",
    "                        break\n",
    "\n",
    "            if self.quit:\n",
    "                break\n",
    "\n",
    "    def render(self):\n",
    "        # Clear screen\n",
    "        self.screen.fill(self.bg_color)\n",
    "\n",
    "        # Draw elements\n",
    "        # * Static elements\n",
    "        for road in self.env.roads:\n",
    "            pygame.draw.line(self.screen, self.road_color, (road[0][0] * self.env.block_size, road[0][1] * self.env.block_size), (road[1][0] * self.env.block_size, road[1][1] * self.env.block_size), self.road_width)\n",
    "\n",
    "        for intersection, traffic_light in self.env.intersections.iteritems():\n",
    "            pygame.draw.circle(self.screen, self.road_color, (intersection[0] * self.env.block_size, intersection[1] * self.env.block_size), 10)\n",
    "            if traffic_light.state:  # North-South is open\n",
    "                pygame.draw.line(self.screen, self.colors['green'],\n",
    "                    (intersection[0] * self.env.block_size, intersection[1] * self.env.block_size - 15),\n",
    "                    (intersection[0] * self.env.block_size, intersection[1] * self.env.block_size + 15), self.road_width)\n",
    "            else:  # East-West is open\n",
    "                pygame.draw.line(self.screen, self.colors['green'],\n",
    "                    (intersection[0] * self.env.block_size - 15, intersection[1] * self.env.block_size),\n",
    "                    (intersection[0] * self.env.block_size + 15, intersection[1] * self.env.block_size), self.road_width)\n",
    "\n",
    "        # * Dynamic elements\n",
    "        for agent, state in self.env.agent_states.iteritems():\n",
    "            # Compute precise agent location here (back from the intersection some)\n",
    "            agent_offset = (2 * state['heading'][0] * self.agent_circle_radius, 2 * state['heading'][1] * self.agent_circle_radius)\n",
    "            agent_pos = (state['location'][0] * self.env.block_size - agent_offset[0], state['location'][1] * self.env.block_size - agent_offset[1])\n",
    "            agent_color = self.colors[agent.color]\n",
    "            if hasattr(agent, '_sprite') and agent._sprite is not None:\n",
    "                # Draw agent sprite (image), properly rotated\n",
    "                rotated_sprite = agent._sprite if state['heading'] == (1, 0) else pygame.transform.rotate(agent._sprite, 180 if state['heading'][0] == -1 else state['heading'][1] * -90)\n",
    "                self.screen.blit(rotated_sprite,\n",
    "                    pygame.rect.Rect(agent_pos[0] - agent._sprite_size[0] / 2, agent_pos[1] - agent._sprite_size[1] / 2,\n",
    "                        agent._sprite_size[0], agent._sprite_size[1]))\n",
    "            else:\n",
    "                # Draw simple agent (circle with a short line segment poking out to indicate heading)\n",
    "                pygame.draw.circle(self.screen, agent_color, agent_pos, self.agent_circle_radius)\n",
    "                pygame.draw.line(self.screen, agent_color, agent_pos, state['location'], self.road_width)\n",
    "            if agent.get_next_waypoint() is not None:\n",
    "                self.screen.blit(self.font.render(agent.get_next_waypoint(), True, agent_color, self.bg_color), (agent_pos[0] + 10, agent_pos[1] + 10))\n",
    "            if state['destination'] is not None:\n",
    "                pygame.draw.circle(self.screen, agent_color, (state['destination'][0] * self.env.block_size, state['destination'][1] * self.env.block_size), 6)\n",
    "                pygame.draw.circle(self.screen, agent_color, (state['destination'][0] * self.env.block_size, state['destination'][1] * self.env.block_size), 15, 2)\n",
    "\n",
    "        # * Overlays\n",
    "        text_y = 10\n",
    "        for text in self.env.status_text.split('\\n'):\n",
    "            self.screen.blit(self.font.render(text, True, self.colors['red'], self.bg_color), (100, text_y))\n",
    "            text_y += 20\n",
    "\n",
    "        # Flip buffers\n",
    "        pygame.display.flip()\n",
    "\n",
    "    def pause(self):\n",
    "        abs_pause_time = time.time()\n",
    "        pause_text = \"[PAUSED] Press any key to continue...\"\n",
    "        self.screen.blit(self.font.render(pause_text, True, self.colors['cyan'], self.bg_color), (100, self.height - 40))\n",
    "        pygame.display.flip()\n",
    "        print pause_text  # [debug]\n",
    "        while self.paused:\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.KEYDOWN:\n",
    "                    self.paused = False\n",
    "            pygame.time.wait(self.frame_delay)\n",
    "        self.screen.blit(self.font.render(pause_text, True, self.bg_color, self.bg_color), (100, self.height - 40))\n",
    "        self.start_time += (time.time() - abs_pause_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
